[
  {
    "id": "FUNC-LIST-1",
    "code": "def remove_duplicates(lst):\n    result = []\n    for item in lst:\n        if item not in result:\n            result.append(item)\n    return result",
    "correct_code": "def remove_duplicates(lst):\n    return list(dict.fromkeys(lst))",
    "requirement": "Remove duplicates from a list while preserving order",
    "function_name": "remove_duplicates",
    "type": "functional",
    "category": "Data Processing",
    "source": "HumanEval",
    "reference": "https://github.com/openai/human-eval"
  },
  {
    "id": "FUNC-STR-1",
    "code": "def is_palindrome(s):\n    return s == s[::-1]",
    "correct_code": "def is_palindrome(s):\n    s = ''.join(c.lower() for c in s if c.isalnum())\n    return s == s[::-1]",
    "requirement": "Check if a string is a palindrome (ignoring case and non-alphanumeric characters)",
    "function_name": "is_palindrome",
    "type": "functional",
    "category": "String Processing",
    "source": "LeetCode",
    "reference": "https://leetcode.com/problems/valid-palindrome/"
  },
  {
    "id": "FUNC-MATH-1",
    "code": "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)",
    "correct_code": "def fibonacci(n):\n    if n <= 1:\n        return n\n    a, b = 0, 1\n    for _ in range(2, n + 1):\n        a, b = b, a + b\n    return b",
    "requirement": "Calculate the nth Fibonacci number efficiently",
    "function_name": "fibonacci",
    "type": "functional",
    "category": "Algorithm",
    "source": "MBPP",
    "reference": "https://github.com/google-research/google-research/tree/master/mbpp"
  },
  {
    "id": "FUNC-SORT-1",
    "code": "def merge_sorted_lists(list1, list2):\n    result = list1 + list2\n    result.sort()\n    return result",
    "correct_code": "def merge_sorted_lists(list1, list2):\n    result = []\n    i = j = 0\n    while i < len(list1) and j < len(list2):\n        if list1[i] <= list2[j]:\n            result.append(list1[i])\n            i += 1\n        else:\n            result.append(list2[j])\n            j += 1\n    result.extend(list1[i:])\n    result.extend(list2[j:])\n    return result",
    "requirement": "Merge two sorted lists efficiently in O(n+m) time",
    "function_name": "merge_sorted_lists",
    "type": "functional",
    "category": "Algorithm",
    "source": "CodeContest",
    "reference": "https://github.com/deepmind/code_contests"
  },
  {
    "id": "FUNC-DICT-1",
    "code": "def count_words(text):\n    words = text.split()\n    word_count = {}\n    for word in words:\n        if word in word_count:\n            word_count[word] += 1\n        else:\n            word_count[word] = 1\n    return word_count",
    "correct_code": "def count_words(text):\n    from collections import Counter\n    import re\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    return dict(Counter(words))",
    "requirement": "Count word occurrences in text (case-insensitive, handle punctuation)",
    "function_name": "count_words",
    "type": "functional",
    "category": "Text Processing",
    "source": "HumanEval",
    "reference": "https://github.com/openai/human-eval"
  },
  {
    "id": "FUNC-VALIDATION-1",
    "code": "def validate_email(email):\n    return '@' in email and '.' in email",
    "correct_code": "def validate_email(email):\n    import re\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return re.match(pattern, email) is not None",
    "requirement": "Validate email address format properly",
    "function_name": "validate_email",
    "type": "functional",
    "category": "Validation",
    "source": "LeetCode",
    "reference": "https://leetcode.com/problems/validate-ip-address/"
  },
  {
    "id": "FUNC-SEARCH-1",
    "code": "def binary_search(arr, target):\n    for i, val in enumerate(arr):\n        if val == target:\n            return i\n    return -1",
    "correct_code": "def binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return -1",
    "requirement": "Implement binary search on a sorted array",
    "function_name": "binary_search",
    "type": "functional",
    "category": "Search Algorithm",
    "source": "MBPP",
    "reference": "https://github.com/google-research/google-research/tree/master/mbpp"
  },
  {
    "id": "FUNC-DATE-1",
    "code": "def days_between(date1, date2):\n    # Assumes format 'YYYY-MM-DD'\n    y1, m1, d1 = map(int, date1.split('-'))\n    y2, m2, d2 = map(int, date2.split('-'))\n    # Simplified calculation (incorrect for different months/years)\n    return abs(d2 - d1)",
    "correct_code": "def days_between(date1, date2):\n    from datetime import datetime\n    d1 = datetime.strptime(date1, '%Y-%m-%d')\n    d2 = datetime.strptime(date2, '%Y-%m-%d')\n    return abs((d2 - d1).days)",
    "requirement": "Calculate days between two dates accurately",
    "function_name": "days_between",
    "type": "functional",
    "category": "Date Processing",
    "source": "CodeContest",
    "reference": "https://github.com/deepmind/code_contests"
  },
  {
    "id": "FUNC-JSON-1",
    "code": "def parse_json(json_string):\n    import json\n    data = json.loads(json_string)\n    return data['result']['value']",
    "correct_code": "def parse_json(json_string):\n    import json\n    try:\n        data = json.loads(json_string)\n        if 'result' not in data:\n            raise ValueError(\"Missing 'result' key\")\n        if 'value' not in data['result']:\n            raise ValueError(\"Missing 'value' key\")\n        return data['result']['value']\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON: {e}\")",
    "requirement": "Safely extract nested value from JSON with error handling",
    "function_name": "parse_json",
    "type": "functional",
    "category": "Data Parsing",
    "source": "HumanEval",
    "reference": "https://github.com/openai/human-eval"
  },
  {
    "id": "FUNC-CACHE-1",
    "code": "def expensive_calculation(n):\n    # Simulates expensive operation\n    if n <= 1:\n        return 1\n    return expensive_calculation(n-1) + expensive_calculation(n-2) + n",
    "correct_code": "def expensive_calculation(n, cache={}):\n    if n in cache:\n        return cache[n]\n    if n <= 1:\n        result = 1\n    else:\n        result = expensive_calculation(n-1, cache) + expensive_calculation(n-2, cache) + n\n    cache[n] = result\n    return result",
    "requirement": "Optimize recursive function with memoization",
    "function_name": "expensive_calculation",
    "type": "functional",
    "category": "Optimization",
    "source": "LeetCode",
    "reference": "https://leetcode.com/problems/climbing-stairs/"
  },
  {
    "id": "FUNC-ARRAY-1",
    "code": "def find_max_subarray_sum(arr):\n    max_sum = 0\n    for i in range(len(arr)):\n        for j in range(i, len(arr)):\n            current_sum = sum(arr[i:j+1])\n            max_sum = max(max_sum, current_sum)\n    return max_sum",
    "correct_code": "def find_max_subarray_sum(arr):\n    if not arr:\n        return 0\n    max_sum = current_sum = arr[0]\n    for i in range(1, len(arr)):\n        current_sum = max(arr[i], current_sum + arr[i])\n        max_sum = max(max_sum, current_sum)\n    return max_sum",
    "requirement": "Find maximum sum of contiguous subarray (Kadane's algorithm)",
    "function_name": "find_max_subarray_sum",
    "type": "functional",
    "category": "Algorithm",
    "source": "MBPP",
    "reference": "https://github.com/google-research/google-research/tree/master/mbpp"
  },
  {
    "id": "FUNC-TREE-1",
    "code": "def flatten_dict(d):\n    result = {}\n    for key, value in d.items():\n        if isinstance(value, dict):\n            result.update(flatten_dict(value))\n        else:\n            result[key] = value\n    return result",
    "correct_code": "def flatten_dict(d, parent_key='', sep='.'):\n    items = []\n    for k, v in d.items():\n        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n        if isinstance(v, dict):\n            items.extend(flatten_dict(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)",
    "requirement": "Flatten nested dictionary with dot notation keys",
    "function_name": "flatten_dict",
    "type": "functional",
    "category": "Data Processing",
    "source": "CodeContest",
    "reference": "https://github.com/deepmind/code_contests"
  },
  {
    "id": "FUNC-REGEX-1",
    "code": "def extract_phone_numbers(text):\n    import re\n    pattern = r'\\d{3}-\\d{3}-\\d{4}'\n    return re.findall(pattern, text)",
    "correct_code": "def extract_phone_numbers(text):\n    import re\n    patterns = [\n        r'\\(\\d{3}\\)\\s*\\d{3}-\\d{4}',  # (123) 456-7890\n        r'\\d{3}-\\d{3}-\\d{4}',        # 123-456-7890\n        r'\\d{3}\\.\\d{3}\\.\\d{4}',     # 123.456.7890\n        r'\\d{10}'                    # 1234567890\n    ]\n    numbers = []\n    for pattern in patterns:\n        numbers.extend(re.findall(pattern, text))\n    return numbers",
    "requirement": "Extract phone numbers in various formats from text",
    "function_name": "extract_phone_numbers",
    "type": "functional",
    "category": "Text Processing",
    "source": "HumanEval",
    "reference": "https://github.com/openai/human-eval"
  },
  {
    "id": "FUNC-STAT-1",
    "code": "def calculate_statistics(numbers):\n    mean = sum(numbers) / len(numbers)\n    return {'mean': mean}",
    "correct_code": "def calculate_statistics(numbers):\n    if not numbers:\n        return {'mean': 0, 'median': 0, 'std_dev': 0}\n    \n    mean = sum(numbers) / len(numbers)\n    sorted_nums = sorted(numbers)\n    n = len(sorted_nums)\n    median = sorted_nums[n//2] if n % 2 == 1 else (sorted_nums[n//2-1] + sorted_nums[n//2]) / 2\n    \n    variance = sum((x - mean) ** 2 for x in numbers) / len(numbers)\n    std_dev = variance ** 0.5\n    \n    return {'mean': mean, 'median': median, 'std_dev': std_dev}",
    "requirement": "Calculate comprehensive statistics with proper edge case handling",
    "function_name": "calculate_statistics",
    "type": "functional",
    "category": "Mathematical",
    "source": "LeetCode",
    "reference": "https://leetcode.com/problems/statistics-from-a-large-sample/"
  },
  {
    "id": "FUNC-URL-1",
    "code": "def parse_url(url):\n    parts = url.split('/')\n    return {'domain': parts[2], 'path': '/'.join(parts[3:])}",
    "correct_code": "def parse_url(url):\n    from urllib.parse import urlparse\n    parsed = urlparse(url)\n    return {\n        'scheme': parsed.scheme,\n        'domain': parsed.netloc,\n        'path': parsed.path,\n        'query': parsed.query,\n        'fragment': parsed.fragment\n    }",
    "requirement": "Parse URL into components handling various URL formats",
    "function_name": "parse_url",
    "type": "functional",
    "category": "Data Parsing",
    "source": "MBPP",
    "reference": "https://github.com/google-research/google-research/tree/master/mbpp"
  },
  {
    "id": "FUNC-ASYNC-1",
    "code": "def process_items(items):\n    results = []\n    for item in items:\n        result = expensive_api_call(item)\n        results.append(result)\n    return results",
    "correct_code": "async def process_items(items):\n    import asyncio\n    async def process_item(item):\n        return await expensive_api_call_async(item)\n    \n    tasks = [process_item(item) for item in items]\n    results = await asyncio.gather(*tasks)\n    return results",
    "requirement": "Process items concurrently for better performance",
    "function_name": "process_items",
    "type": "functional",
    "category": "Concurrency",
    "source": "CodeContest",
    "reference": "https://github.com/deepmind/code_contests"
  },
  {
    "id": "FUNC-MEMORY-1",
    "code": "def read_large_file(filename):\n    with open(filename, 'r') as f:\n        content = f.read()\n    return content.split('\\n')",
    "correct_code": "def read_large_file(filename):\n    def line_generator():\n        with open(filename, 'r') as f:\n            for line in f:\n                yield line.strip()\n    return line_generator()",
    "requirement": "Read large files memory-efficiently using generators",
    "function_name": "read_large_file",
    "type": "functional",
    "category": "Memory Optimization",
    "source": "HumanEval",
    "reference": "https://github.com/openai/human-eval"
  },
  {
    "id": "FUNC-GRAPH-1",
    "code": "def find_shortest_path(graph, start, end):\n    # Simple DFS approach (inefficient)\n    def dfs(current, target, path, visited):\n        if current == target:\n            return path\n        visited.add(current)\n        for neighbor in graph.get(current, []):\n            if neighbor not in visited:\n                result = dfs(neighbor, target, path + [neighbor], visited)\n                if result:\n                    return result\n        return None\n    return dfs(start, end, [start], set())",
    "correct_code": "def find_shortest_path(graph, start, end):\n    from collections import deque\n    queue = deque([(start, [start])])\n    visited = {start}\n    \n    while queue:\n        current, path = queue.popleft()\n        if current == end:\n            return path\n        \n        for neighbor in graph.get(current, []):\n            if neighbor not in visited:\n                visited.add(neighbor)\n                queue.append((neighbor, path + [neighbor]))\n    \n    return None",
    "requirement": "Find shortest path in unweighted graph using BFS",
    "function_name": "find_shortest_path",
    "type": "functional",
    "category": "Graph Algorithm",
    "source": "LeetCode",
    "reference": "https://leetcode.com/problems/shortest-path-in-binary-matrix/"
  },
  {
    "id": "FUNC-ENCODING-1",
    "code": "def encode_decode_string(text, operation='encode'):\n    if operation == 'encode':\n        return text.encode('utf-8')\n    else:\n        return text.decode('utf-8')",
    "correct_code": "def encode_decode_string(text, operation='encode', encoding='utf-8'):\n    try:\n        if operation == 'encode':\n            if isinstance(text, str):\n                return text.encode(encoding)\n            else:\n                raise TypeError(\"Input must be string for encoding\")\n        elif operation == 'decode':\n            if isinstance(text, bytes):\n                return text.decode(encoding)\n            else:\n                raise TypeError(\"Input must be bytes for decoding\")\n        else:\n            raise ValueError(\"Operation must be 'encode' or 'decode'\")\n    except UnicodeError as e:\n        raise ValueError(f\"Encoding/decoding error: {e}\")",
    "requirement": "Safely encode/decode strings with proper error handling",
    "function_name": "encode_decode_string",
    "type": "functional",
    "category": "Text Processing",
    "source": "MBPP",
    "reference": "https://github.com/google-research/google-research/tree/master/mbpp"
  },
  {
    "id": "FUNC-MATRIX-1",
    "code": "def matrix_multiply(A, B):\n    result = []\n    for i in range(len(A)):\n        row = []\n        for j in range(len(B[0])):\n            sum_val = 0\n            for k in range(len(B)):\n                sum_val += A[i][k] * B[k][j]\n            row.append(sum_val)\n        result.append(row)\n    return result",
    "correct_code": "def matrix_multiply(A, B):\n    if not A or not B or not A[0] or not B[0]:\n        raise ValueError(\"Empty matrices\")\n    \n    if len(A[0]) != len(B):\n        raise ValueError(\"Incompatible matrix dimensions\")\n    \n    rows_A, cols_A = len(A), len(A[0])\n    rows_B, cols_B = len(B), len(B[0])\n    \n    result = [[0 for _ in range(cols_B)] for _ in range(rows_A)]\n    \n    for i in range(rows_A):\n        for j in range(cols_B):\n            for k in range(cols_A):\n                result[i][j] += A[i][k] * B[k][j]\n    \n    return result",
    "requirement": "Multiply matrices with proper dimension validation",
    "function_name": "matrix_multiply",
    "type": "functional",
    "category": "Mathematical",
    "source": "CodeContest",
    "reference": "https://github.com/deepmind/code_contests"
  },
  {
    "id": "FUNC-SCHEDULER-1",
    "code": "def schedule_tasks(tasks):\n    # Simple FIFO scheduling\n    return sorted(tasks, key=lambda x: x['arrival_time'])",
    "correct_code": "def schedule_tasks(tasks):\n    # Shortest Job First scheduling\n    if not tasks:\n        return []\n    \n    # Sort by arrival time first, then by duration for SJF\n    sorted_tasks = sorted(tasks, key=lambda x: (x['arrival_time'], x['duration']))\n    \n    scheduled = []\n    current_time = 0\n    \n    while sorted_tasks:\n        # Find tasks that have arrived\n        available = [t for t in sorted_tasks if t['arrival_time'] <= current_time]\n        \n        if not available:\n            # Jump to next arrival time\n            current_time = min(t['arrival_time'] for t in sorted_tasks)\n            continue\n        \n        # Select shortest job\n        next_task = min(available, key=lambda x: x['duration'])\n        sorted_tasks.remove(next_task)\n        \n        next_task['start_time'] = current_time\n        next_task['completion_time'] = current_time + next_task['duration']\n        current_time = next_task['completion_time']\n        \n        scheduled.append(next_task)\n    \n    return scheduled",
    "requirement": "Implement Shortest Job First task scheduling algorithm",
    "function_name": "schedule_tasks",
    "type": "functional",
    "category": "Algorithm",
    "source": "HumanEval",
    "reference": "https://github.com/openai/human-eval"
  },
  {
    "id": "FUNC-COMPRESS-1",
    "code": "def compress_string(text):\n    if not text:\n        return text\n    \n    compressed = []\n    current_char = text[0]\n    count = 1\n    \n    for char in text[1:]:\n        if char == current_char:\n            count += 1\n        else:\n            compressed.append(current_char + str(count))\n            current_char = char\n            count = 1\n    \n    compressed.append(current_char + str(count))\n    return ''.join(compressed)",
    "correct_code": "def compress_string(text):\n    if not text:\n        return text\n    \n    compressed = []\n    current_char = text[0]\n    count = 1\n    \n    for char in text[1:]:\n        if char == current_char:\n            count += 1\n        else:\n            if count == 1:\n                compressed.append(current_char)\n            else:\n                compressed.append(current_char + str(count))\n            current_char = char\n            count = 1\n    \n    # Handle last group\n    if count == 1:\n        compressed.append(current_char)\n    else:\n        compressed.append(current_char + str(count))\n    \n    result = ''.join(compressed)\n    return result if len(result) < len(text) else text",
    "requirement": "Compress string using run-length encoding (only if shorter)",
    "function_name": "compress_string",
    "type": "functional",
    "category": "String Processing",
    "source": "LeetCode",
    "reference": "https://leetcode.com/problems/string-compression/"
  },
  {
    "id": "FUNC-POOL-1",
    "code": "def object_pool_manager():\n    pool = []\n    \n    def get_object():\n        if pool:\n            return pool.pop()\n        else:\n            return create_new_object()\n    \n    def return_object(obj):\n        pool.append(obj)\n    \n    return get_object, return_object",
    "correct_code": "def object_pool_manager(max_size=10):\n    pool = []\n    in_use = set()\n    \n    def get_object():\n        if pool:\n            obj = pool.pop()\n        else:\n            obj = create_new_object()\n        \n        in_use.add(id(obj))\n        return obj\n    \n    def return_object(obj):\n        obj_id = id(obj)\n        if obj_id in in_use:\n            in_use.remove(obj_id)\n            if len(pool) < max_size:\n                # Reset object state before returning to pool\n                reset_object(obj)\n                pool.append(obj)\n        else:\n            raise ValueError(\"Object not from this pool\")\n    \n    def get_stats():\n        return {'pool_size': len(pool), 'in_use': len(in_use)}\n    \n    return get_object, return_object, get_stats",
    "requirement": "Implement object pool with size limits and tracking",
    "function_name": "object_pool_manager",
    "type": "functional",
    "category": "Design Pattern",
    "source": "MBPP",
    "reference": "https://github.com/google-research/google-research/tree/master/mbpp"
  },
  {
    "id": "FUNC-RATE-1",
    "code": "def rate_limiter(max_requests, time_window):\n    requests = []\n    \n    def is_allowed():\n        import time\n        current_time = time.time()\n        # Remove old requests\n        while requests and requests[0] < current_time - time_window:\n            requests.pop(0)\n        \n        if len(requests) < max_requests:\n            requests.append(current_time)\n            return True\n        return False\n    \n    return is_allowed",
    "correct_code": "def rate_limiter(max_requests, time_window):\n    from collections import deque\n    import time\n    \n    requests = deque()\n    \n    def is_allowed(user_id=None):\n        current_time = time.time()\n        \n        # Remove requests outside the time window\n        while requests and requests[0] <= current_time - time_window:\n            requests.popleft()\n        \n        if len(requests) < max_requests:\n            requests.append(current_time)\n            return True\n        \n        return False\n    \n    def get_wait_time():\n        if not requests:\n            return 0\n        \n        current_time = time.time()\n        oldest_request = requests[0]\n        \n        if len(requests) >= max_requests:\n            return max(0, time_window - (current_time - oldest_request))\n        \n        return 0\n    \n    return is_allowed, get_wait_time",
    "requirement": "Implement sliding window rate limiter with wait time calculation",
    "function_name": "rate_limiter",
    "type": "functional",
    "category": "System Design",
    "source": "CodeContest",
    "reference": "https://github.com/deepmind/code_contests"
  },
  {
    "id": "FUNC-TREE-2",
    "code": "def binary_tree_traversal(root, order='inorder'):\n    if not root:\n        return []\n    \n    if order == 'inorder':\n        return binary_tree_traversal(root.left, order) + [root.val] + binary_tree_traversal(root.right, order)\n    elif order == 'preorder':\n        return [root.val] + binary_tree_traversal(root.left, order) + binary_tree_traversal(root.right, order)\n    elif order == 'postorder':\n        return binary_tree_traversal(root.left, order) + binary_tree_traversal(root.right, order) + [root.val]",
    "correct_code": "def binary_tree_traversal(root, order='inorder'):\n    def inorder_iterative(node):\n        stack, result = [], []\n        current = node\n        \n        while stack or current:\n            while current:\n                stack.append(current)\n                current = current.left\n            \n            current = stack.pop()\n            result.append(current.val)\n            current = current.right\n        \n        return result\n    \n    def preorder_iterative(node):\n        if not node:\n            return []\n        \n        stack, result = [node], []\n        \n        while stack:\n            current = stack.pop()\n            result.append(current.val)\n            \n            if current.right:\n                stack.append(current.right)\n            if current.left:\n                stack.append(current.left)\n        \n        return result\n    \n    def postorder_iterative(node):\n        if not node:\n            return []\n        \n        stack, result = [node], []\n        \n        while stack:\n            current = stack.pop()\n            result.append(current.val)\n            \n            if current.left:\n                stack.append(current.left)\n            if current.right:\n                stack.append(current.right)\n        \n        return result[::-1]\n    \n    if not root:\n        return []\n    \n    if order == 'inorder':\n        return inorder_iterative(root)\n    elif order == 'preorder':\n        return preorder_iterative(root)\n    elif order == 'postorder':\n        return postorder_iterative(root)\n    else:\n        raise ValueError(\"Order must be 'inorder', 'preorder', or 'postorder'\")",
    "requirement": "Implement iterative binary tree traversal to avoid stack overflow",
    "function_name": "binary_tree_traversal",
    "type": "functional",
    "category": "Tree Algorithm",
    "source": "LeetCode",
    "reference": "https://leetcode.com/problems/binary-tree-inorder-traversal/"
  },
  {
    "id": "FUNC-RETRY-1",
    "code": "def retry_operation(func, max_attempts=3):\n    for attempt in range(max_attempts):\n        try:\n            return func()\n        except Exception as e:\n            if attempt == max_attempts - 1:\n                raise e\n    return None",
    "correct_code": "def retry_operation(func, max_attempts=3, delay=1, backoff=2, exceptions=(Exception,)):\n    import time\n    import random\n    \n    for attempt in range(max_attempts):\n        try:\n            return func()\n        except exceptions as e:\n            if attempt == max_attempts - 1:\n                raise e\n            \n            # Exponential backoff with jitter\n            wait_time = delay * (backoff ** attempt) + random.uniform(0, 1)\n            time.sleep(wait_time)\n            \n            print(f\"Attempt {attempt + 1} failed: {e}. Retrying in {wait_time:.2f}s...\")\n    \n    return None",
    "requirement": "Implement robust retry mechanism with exponential backoff",
    "function_name": "retry_operation",
    "type": "functional",
    "category": "Error Handling",
    "source": "HumanEval",
    "reference": "https://github.com/openai/human-eval"
  },
  {
    "id": "FUNC-BALANCE-1",
    "code": "def is_balanced_parentheses(s):\n    count = 0\n    for char in s:\n        if char == '(':\n            count += 1\n        elif char == ')':\n            count -= 1\n    return count == 0",
    "correct_code": "def is_balanced_parentheses(s):\n    stack = []\n    mapping = {')': '(', '}': '{', ']': '['}\n    \n    for char in s:\n        if char in mapping.values():  # Opening brackets\n            stack.append(char)\n        elif char in mapping.keys():  # Closing brackets\n            if not stack or stack.pop() != mapping[char]:\n                return False\n    \n    return len(stack) == 0",
    "requirement": "Check if string has balanced parentheses/brackets of all types",
    "function_name": "is_balanced_parentheses",
    "type": "functional",
    "category": "String Processing",
    "source": "LeetCode",
    "reference": "https://leetcode.com/problems/valid-parentheses/"
  },
  {
    "id": "FUNC-LRU-1",
    "code": "def lru_cache_simple(max_size):\n    cache = {}\n    \n    def get(key):\n        return cache.get(key)\n    \n    def put(key, value):\n        if len(cache) >= max_size and key not in cache:\n            # Remove first item (not truly LRU)\n            first_key = next(iter(cache))\n            del cache[first_key]\n        cache[key] = value\n    \n    return get, put",
    "correct_code": "def lru_cache_simple(max_size):\n    from collections import OrderedDict\n    \n    cache = OrderedDict()\n    \n    def get(key):\n        if key in cache:\n            # Move to end (most recently used)\n            cache.move_to_end(key)\n            return cache[key]\n        return None\n    \n    def put(key, value):\n        if key in cache:\n            # Update existing key\n            cache[key] = value\n            cache.move_to_end(key)\n        else:\n            # Add new key\n            if len(cache) >= max_size:\n                # Remove least recently used (first item)\n                cache.popitem(last=False)\n            cache[key] = value\n    \n    def get_stats():\n        return {'size': len(cache), 'keys': list(cache.keys())}\n    \n    return get, put, get_stats",
    "requirement": "Implement LRU cache with proper eviction policy",
    "function_name": "lru_cache_simple",
    "type": "functional",
    "category": "Data Structure",
    "source": "LeetCode",
    "reference": "https://leetcode.com/problems/lru-cache/"
  }
]